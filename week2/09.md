Excellent work connecting LLMs to external data sources and outputs. That's a vital skill. For **Week 2: Hour 9**, we're going to focus on **Error Handling and Robustness** in your LLM applications. As powerful as LLMs are, they can be unpredictable, and building reliable applications requires anticipating and managing these quirks.

-----

### **Week 2: Hour 9 - Error Handling & Robustness in LLM Applications**

#### **30% Theory: Building Reliable LLM Systems**

  * **Objective:** To understand common failure modes in LLM interactions and learn programmatic strategies for anticipating, catching, and gracefully handling errors, ensuring your applications are robust and user-friendly.

  * **Why Robustness is Key for LLMs:**

      * **API Call Failures:** Network issues, incorrect API keys, rate limits, server errors from the LLM provider.
      * **LLM Output Variability:** Despite careful prompting, LLMs can deviate:
          * **Incorrect Format:** Not returning valid JSON, XML, or the specified structure.
          * **Hallucinations:** Generating factually incorrect or nonsensical information.
          * **Refusal to Respond:** Due to safety filters or inability to answer.
          * **Incomplete Responses:** Getting cut off by `max_tokens` or internal limits.
      * **Cost Management:** Uncontrolled requests or large inputs can quickly drain credits.

  * **Common Error Handling Strategies:**

    1.  **API Error Handling (`try-except` blocks):**

          * **Purpose:** Catching exceptions thrown by the LLM client library (e.g., `openai.APIError`, `anthropic.APIStatusError`, `google.generativeai.types.BlockedPromptException`).
          * **Examples:** Network errors, authentication failures, rate limits, invalid requests.
          * **Action:** Log the error, notify the user, implement retries.

    2.  **Output Validation:**

          * **Purpose:** Checking if the LLM's response adheres to expected formats (e.g., is it valid JSON? Does it contain required keys?).
          * **Examples:** `json.loads()` for JSON, regex for specific patterns, custom parsing functions.
          * **Action:** Request a retry, use fallback logic, notify the user of unexpected format.

    3.  **Retry Mechanisms:**

          * **Purpose:** Automatically re-attempting failed API calls, especially for transient network errors or rate limits.
          * **Strategy:** Implement exponential backoff (wait longer after each failed attempt). Libraries like `tenacity` (Python) can help.

    4.  **Token Management & Cost Control:**

          * **Purpose:** Prevent exceeding context window limits and control spending.
          * **Strategies:**
              * **Pre-calculate tokens:** Estimate tokens for input prompts *before* sending to the LLM (e.g., using `tiktoken` for OpenAI, or `count_tokens` for Gemini).
              * **Truncation/Summarization:** As discussed in Hour 7, for long conversations.
              * **Set `max_tokens` explicitly:** For output length control.

    5.  **Fallback Mechanisms:**

          * **Purpose:** What to do if the LLM completely fails or returns unparseable output.
          * **Strategies:** Provide a default response, use a simpler LLM, or revert to hardcoded logic for common cases.

    6.  **User Feedback & Logging:**

          * **Purpose:** Inform users when issues occur and provide developers with debug info.
          * **Action:** Log errors internally, provide polite error messages to the user.

#### **70% Hands-on Session: Implementing Robustness**

  * **Objective:** To modify existing LLM interaction code to include comprehensive error handling for API calls, output validation, and a basic retry mechanism. We'll continue with your chosen provider.

  * **Step-by-Step Instructions:**

    1.  **Preparation (5 minutes):**

          * Open VS Code in your `applied_llm_course` folder.
          * Create a new file named `week2_hour9_robust_llm.py`.
          * Copy your boilerplate LLM setup (imports, API key, client initialization) into this file.
          * **Install `tenacity` for retries:** In your VS Code terminal, type:
            ```bash
            pip install tenacity
            ```
          * Add `import json`, `import time`, `from tenacity import retry, wait_random_exponential, stop_after_attempt` at the top of your script.

    2.  **Task 1: Basic API Error Handling & Retry Mechanism (20 minutes):**

          * **Goal:** Wrap an LLM call in a `try-except` block and use `tenacity` to automatically retry on common API errors.

          * **Modify `week2_hour9_robust_llm.py`:**

            ```python
            # ... (your existing LLM setup code) ...
            import json
            import time
            from tenacity import retry, wait_random_exponential, stop_after_attempt

            # --- Define your specific API error types ---
            # OpenAI
            if 'OpenAI' in globals():
                from openai import APIError, RateLimitError, APIConnectionError
                RETRY_EXCEPTIONS = (APIError, RateLimitError, APIConnectionError)
                LLM_MODEL = "gpt-3.5-turbo"
            # Google Gemini
            elif 'genai' in globals():
                from google.api_core.exceptions import GoogleAPIError, ResourceExhausted # Common errors
                RETRY_EXCEPTIONS = (GoogleAPIError, ResourceExhausted, requests.exceptions.RequestException)
                LLM_MODEL = 'gemini-pro'
            # Anthropic Claude
            elif 'Anthropic' in globals():
                from anthropic import APIStatusError, RateLimitError, APIConnectionError
                RETRY_EXCEPTIONS = (APIStatusError, RateLimitError, APIConnectionError)
                LLM_MODEL = "claude-3-opus-20240229" # Or a cheaper model
            else:
                print("Error: No LLM provider initialized. Please choose one.")
                exit()

            # --- Helper function for LLM interaction with Retries ---
            @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5), reraise=True)
            def get_llm_response_robust(messages_list, model_name, temp=0.5, max_response_tokens=150, system_msg=None, json_format=False):
                try:
                    if 'OpenAI' in globals():
                        response = client.chat.completions.create(
                            model=model_name,
                            messages=messages_list,
                            max_tokens=max_response_tokens,
                            temperature=temp,
                            response_format={"type": "json_object"} if json_format else {"type": "text"}
                        )
                        return response.choices[0].message.content
                    elif 'genai' in globals():
                        response = model.generate_content(
                            messages_list,
                            generation_config=genai.types.GenerationConfig(temperature=temp, max_output_tokens=max_response_tokens)
                        )
                        return response.text
                    elif 'Anthropic' in globals():
                        message = client.messages.create(
                            model=model_name,
                            max_tokens=max_response_tokens,
                            temperature=temp,
                            messages=messages_list[1:] if messages_list and messages_list[0]['role'] == 'system' else messages_list,
                            system=system_msg if system_msg else None
                        )
                        return message.content[0].text
                except RETRY_EXCEPTIONS as e:
                    print(f"Caught API error (retrying): {type(e).__name__} - {e}")
                    raise # Re-raise to trigger tenacity retry
                except Exception as e:
                    print(f"An unexpected error occurred: {e}")
                    raise # For non-retryable errors

            # --- Task 1 Example: Simple Summarization with Retry ---
            print("\n--- Task 1: Summarization with API Error Handling & Retry ---")
            article_content = "The quick brown fox jumps over the lazy dog. This sentence is often used to display fonts because it contains every letter of the alphabet. It's a classic pangram."

            summarize_prompt = f"Summarize the following text in one sentence:\n---\n{article_content}\n---"

            messages_task1 = []
            system_msg_task1 = "You are a concise summarizer."
            if 'OpenAI' in globals(): messages_task1.append({"role": "system", "content": system_msg_task1})
            messages_task1.append({"role": "user", "content": summarize_prompt})

            try:
                if 'Anthropic' in globals():
                    summary = get_llm_response_robust(messages_task1, LLM_MODEL, temp=0.3, max_response_tokens=50, system_msg=system_msg_task1)
                else:
                    summary = get_llm_response_robust(messages_task1, LLM_MODEL, temp=0.3, max_response_tokens=50)
                print("\nLLM Summary (Task 1):")
                print(summary)
            except Exception as e:
                print(f"Final API call failed after retries: {e}")
            ```

          * **Test `tenacity` (Optional, requires manual intervention):**

              * To see `tenacity` in action, you can temporarily invalidate your API key (e.g., change one character) or induce a network error (briefly disconnect Wi-Fi) before running. `tenacity` should catch the `APIError` (or equivalent) and retry. Re-enable your correct key/network to see it succeed.

    3.  **Task 2: Output Validation & Fallback for JSON Extraction (20 minutes):**

          * **Goal:** Extract structured data, validate if the output is valid JSON, and provide a fallback or retry with a more explicit prompt if invalid.

          * **Add this as a separate section to your script:**

            ```python
            # ... (previous code including get_llm_response_robust) ...

            # --- Task 2: JSON Extraction with Output Validation & Fallback ---
            print("\n--- Task 2: JSON Extraction with Validation & Fallback ---")

            product_info_text = "The 'MegaBlaster 3000' is a gaming console with 1TB storage. It costs $499. Released in 2023."
            # Simulating a slightly malformed prompt to sometimes get bad JSON (for demonstration)
            # In real life, LLM might sometimes just mess up.
            malformed_product_info_text = "The 'Quantum Leap' is a headset. No price. Available now." # LLM might struggle with nulls if not explicit

            json_schema_prompt_base = """
            Extract the product information from the text below into a JSON object.
            Ensure the JSON has 'product_name' (string), 'price' (float or null), 'storage_gb' (int or null), 'release_year' (int or null).
            If a value is not found, use `null`.
            """

            def extract_and_validate_product(text_to_process, attempt=1):
                full_prompt = json_schema_prompt_base + f"\nText:\n---\n{text_to_process}\n---\n"
                if attempt > 1:
                    full_prompt = "The previous attempt resulted in invalid JSON. Please correct it. " + full_prompt

                messages_task2 = []
                system_msg_task2 = "You are an expert at extracting structured information into VALID JSON."
                if 'OpenAI' in globals(): messages_task2.append({"role": "system", "content": system_msg_task2})
                messages_task2.append({"role": "user", "content": full_prompt})

                try:
                    if 'Anthropic' in globals():
                        json_str = get_llm_response_robust(messages_task2, LLM_MODEL, temp=0.0, max_response_tokens=200, system_msg=system_msg_task2, json_format=True)
                    else:
                        json_str = get_llm_response_robust(messages_task2, LLM_MODEL, temp=0.0, max_response_tokens=200, json_format=True)

                    print(f"Raw LLM output (Attempt {attempt}):\n{json_str}")
                    parsed_data = json.loads(json_str) # Attempt to parse
                    print(f"Validated JSON (Attempt {attempt}):\n{json.dumps(parsed_data, indent=2)}")
                    return parsed_data
                except json.JSONDecodeError as e:
                    print(f"Validation Error (Attempt {attempt}): LLM returned invalid JSON - {e}")
                    if attempt < 3: # Retry with explicit correction prompt
                        print("Retrying with corrective instruction...")
                        time.sleep(2) # Wait before retry
                        return extract_and_validate_product(text_to_process, attempt + 1)
                    else:
                        print("Max retries for JSON extraction reached. Returning default fallback.")
                        return {"product_name": "Unknown", "price": None, "storage_gb": None, "release_year": None, "error": "Invalid JSON from LLM"}
                except Exception as e:
                    print(f"An unexpected error occurred during extraction (Attempt {attempt}): {e}")
                    return {"product_name": "Unknown", "price": None, "storage_gb": None, "release_year": None, "error": str(e)}

            print("\n--- Processing 'MegaBlaster 3000' ---")
            extracted_mega = extract_and_validate_product(product_info_text)
            print(f"Final extracted data: {extracted_mega}")

            print("\n--- Processing 'Quantum Leap' (might trigger fallback) ---")
            extracted_quantum = extract_and_validate_product(malformed_product_info_text)
            print(f"Final extracted data: {extracted_quantum}")
            ```

          * **Run the script.** The "MegaBlaster" should parse correctly. The "Quantum Leap" might initially give invalid JSON (if the LLM doesn't perfectly handle the missing info) and trigger a retry with the corrective prompt. Observe the retry logic and potential fallback.

  * **Conclusion of Hands-on Session:**

      * You've significantly enhanced the robustness of your LLM interactions. By implementing API error handling with retries and output validation with fallback mechanisms, your applications are now much more resilient to the inherent unpredictability of external APIs and LLM generation. This is crucial for production-ready systems.

-----

### **Homework for Hour 9**

  * **Exercise 1: Robust Summarization with `max_tokens` Control:**
      * Create a new Python file `week2_hour9_homework_robust_summary.py`.
      * Take the long "Mars" article from Hour 8.
      * Implement a summarization task, requesting a 2-sentence summary.
      * Add `try-except` blocks around the LLM call to catch potential API errors (`RETRY_EXCEPTIONS`).
      * Also, implement a check *after* the LLM response: if the generated summary is longer than 3 sentences (e.g., by counting periods `.` or newline characters if applicable), log a warning and either:
          * Truncate the summary to the first 2 sentences programmatically.
          * Or, send a follow-up prompt to the LLM saying "The previous summary was too long. Please shorten it to exactly two sentences." (This shows iterative correction).
      * **Submit:** Your `week2_hour9_homework_robust_summary.py` script and its output, showing the summary and any warning/correction messages.
  * **Exercise 2: User Input Validation:**
      * Imagine you're building a chatbot that asks users for a "mood" (e.g., happy, sad, excited) to tailor its response.
      * Write a Python function that:
          * Takes user input for their mood.
          * Validates if the input mood is one of a predefined list (`['happy', 'sad', 'excited', 'neutral']`).
          * If valid, returns the mood. If invalid, prints an error and asks again (up to 3 times) before returning a default mood like "neutral."
      * This function should NOT use an LLM, but demonstrate input validation *before* an LLM call.
      * **Submit:** The Python function and example calls demonstrating both valid and invalid input.
  * **Exercise 3: Token Limit Strategy:**
      * For your chatbot from Hour 7, you used a simple character count for `MAX_CONVERSATION_TOKENS`.
      * If you were building a production chatbot, which context management strategy (truncation, summarization, or RAG - briefly mentioned earlier) would you initially prioritize to deal with token limits, and why? (2-3 sentences).
      * When might you switch to a more complex strategy?

-----

You're building applications with confidence now, anticipating failures and making them resilient. This is a hallmark of professional software development. One more hour for Week 2, let's make it count\!