Fantastic, you're building a strong foundation in programmatic prompt engineering. Now, in **Week 2: Hour 4**, we're going to tackle a common and incredibly useful pattern: **Extracting Structured Data**. This is where LLMs move beyond just generating text to becoming powerful tools for processing information into a format your applications can easily use.

-----

### **Week 2: Hour 4 - Extracting Structured Data Programmatically**

#### **30% Theory: Turning Free-Form Text into Usable Data**

  * **Objective:** To understand the challenges of extracting structured data from unstructured text using LLMs, and to learn powerful prompting techniques (like JSON/XML formats and schema definitions) to ensure consistent and parseable output.

  * **The Challenge of Structured Extraction:**

      * LLMs are great at generating human-readable text. But applications often need data in a machine-readable format (e.g., a list of items, a table, a JSON object) to then display it, store it in a database, or perform further computations.
      * The challenge is ensuring the LLM *consistently* outputs the data in the exact format your code expects, even with varying inputs.

  * **Key Techniques for Structured Extraction:**

    1.  **Explicit Format Request:**

          * **What it is:** Directly telling the LLM the desired output format (e.g., "Respond in JSON format," "Output as a CSV," "Use a markdown table").
          * **Why it works:** LLMs are trained on massive amounts of structured text, so they recognize these patterns.

    2.  **Schema Definition (JSON Schema / Example JSON):**

          * **What it is:** Providing an example of the *exact structure* (like a template) you expect the JSON or XML output to follow, including data types.
          * **In code:** Embed a sample JSON or a description of a JSON schema within your prompt. This is often the most reliable method.
          * **Example:**
            ````json
            ```json
            {
              "item_name": "string",
              "price": "number",
              ""is_available": "boolean"
            }
            ````
            ```
            Then, for the text: ... extract the information into this JSON format.
            ```
            (Note: OpenAI and some other providers now have dedicated `response_format={"type": "json_object"}` parameters which are even more robust, but explicit prompting still works across all models and is a good foundational skill.)

    3.  **Delimiters for Input & Output:**

          * **Input:** Clearly separate the text to be processed from your instructions using delimiters (`"""`, `---`, `<text>`).
          * **Output:** Ask the LLM to wrap its structured output in delimiters as well (e.g., `json\n...\n`) to make it easier for your code to find and parse.

    4.  **Error Handling (in your code):**

          * Even with perfect prompts, LLMs can sometimes deviate. Your Python code must be prepared to handle cases where the output is *not* perfectly formed JSON/CSV/etc. (e.g., using `try-except` blocks for JSON parsing).

  * **When to Use Which?**

      * For simple lists or tables: Markdown tables or bullet lists are often sufficient.
      * For complex, hierarchical data: JSON is almost always the best choice.
      * For very specific, small extractions: Key-value pairs (`Key: Value`) can work.

#### **70% Hands-on Session: Implementing Structured Data Extraction**

  * **Objective:** To write Python code that prompts an LLM to extract data from unstructured text into a specific, machine-readable format (JSON will be our primary focus) using explicit instructions and schema examples.

  * **Step-by-Step Instructions:**

    1.  **Preparation (5 minutes):**

          * Open VS Code in your `applied_llm_course` folder.
          * Create a new file named `week2_hour4_structured_extraction.py`.
          * Ensure your environment variable for your chosen LLM provider's API key is set in your VS Code terminal.

    2.  **Basic Setup (10 minutes):**

          * Copy the boilerplate for your chosen provider (import statements, API key retrieval, client initialization) into `week2_hour4_structured_extraction.py`.
          * Add `import json` at the top of your script. This will be used to parse JSON outputs.

    3.  **Task 1: Basic JSON Extraction (15 minutes):**

          * **Goal:** Extract simple key-value pairs into a JSON object from a product description.

          * **Modify `week2_hour4_structured_extraction.py`:**

            ```python
            # ... (your existing setup code for your chosen provider) ...
            import json # Add this line at the top

            print("\n--- Basic JSON Extraction Example ---")

            product_description = """
            Introducing the "Aurora Glow Lamp"! This innovative lamp features 7 vibrant LED colors, 3 brightness levels, and a built-in timer for 1 or 2 hours. It's touch-controlled and powered via USB-C. Currently priced at $49.99.
            """

            instructions = f"""
            Extract the following information from the product description below and return it as a JSON object:
            - Product Name
            - Price (as a float)
            - Number of LED colors (as an integer)
            - Has Timer (as a boolean)

            If a piece of information is not found, use `null`.

            Product Description:
            ---
            {product_description}
            ---
            """

            messages = []
            # OpenAI/Anthropic: Often benefit from a system message for clarity, though not strictly required for simple JSON
            if 'OpenAI' in globals():
                messages.append({"role": "system", "content": "You are an expert at extracting product information into JSON."})
            elif 'Anthropic' in globals():
                 system_instruction = "You are an expert at extracting product information into JSON." # Use dedicated system parameter for Claude 3

            messages.append({"role": "user", "content": instructions})

            try:
                if 'OpenAI' in globals():
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=messages,
                        max_tokens=200,
                        temperature=0.0, # Keep low for consistent data extraction
                        response_format={"type": "json_object"} # Use this for guaranteed JSON output (OpenAI specific)
                    )
                    llm_output = response.choices[0].message.content
                elif 'genai' in globals():
                    response = model.generate_content(
                        contents=[{"role": "user", "parts": [instructions]}],
                        generation_config=genai.types.GenerationConfig(temperature=0.0, max_output_tokens=200)
                    )
                    llm_output = response.text
                elif 'Anthropic' in globals():
                    message = client.messages.create(
                        model="claude-3-opus-20240229", # Or a cheaper model
                        max_tokens=200,
                        temperature=0.0,
                        messages=messages, # User content only in messages
                        system=system_instruction if 'system_instruction' in locals() else None # Use if defined
                    )
                    llm_output = message.content[0].text

                print("\nLLM's JSON Output (raw):")
                print(llm_output)

                # Attempt to parse the JSON output
                parsed_data = json.loads(llm_output)
                print("\nParsed JSON Data (Python object):")
                print(parsed_data)
                print(f"Product Name: {parsed_data.get('Product Name')}")
                print(f"Price: ${parsed_data.get('Price', 'N/A')}")

            except json.JSONDecodeError as e:
                print(f"\nError parsing JSON: {e}")
                print("LLM did not return valid JSON.")
            except Exception as e:
                print(f"An error occurred: {e}")
            ```

          * **Run the script.** Observe the raw JSON output and how Python successfully parses it into a dictionary. Note: OpenAI's `response_format={"type": "json_object"}` parameter is very powerful for ensuring valid JSON. Other providers often rely more heavily on strong prompt instructions.

    4.  **Task 2: Schema-Driven Extraction with a Full Example (20 minutes):**

          * **Goal:** Guide the LLM with a complete JSON example including data types for more complex extraction.

          * **Add this as a separate section to your script:**

            ````python
            # ... (your existing setup code) ...
            print("\n--- Schema-Driven JSON Extraction Example ---")

            customer_review = """
            I just received my new 'WhisperFlow Air Purifier' and I'm very impressed! The delivery was super fast, arrived in 2 days. The setup was a breeze, took only 5 minutes. It effectively cleared up pet odors in my living room. I paid $189.99 for it. My only minor complaint is the blue light, it's a bit bright at night. Overall, 4.5/5 stars!
            """

            # Define the desired JSON structure with comments for clarity
            json_schema_example = """
            {
              "product_reviewed": "string",
              "rating": "float (e.g., 4.5)",
              "delivery_time_days": "integer or null if not mentioned",
              "setup_time_minutes": "integer or null if not mentioned",
              "pros": ["list of strings"],
              "cons": ["list of strings"],
              "price_paid": "float or null if not mentioned"
            }
            """

            instructions_schema = f"""
            Extract the following information from the customer review below into a JSON object.
            Strictly follow the JSON schema provided, including data types.
            If a field is not found, use `null` for single values or an empty list `[]` for lists.
            Ensure 'pros' and 'cons' are lists of concise phrases.

            JSON Schema Example:
            ```json
            {json_schema_example}
            ````

            ## Customer Review:

            ## {customer\_review}

            """

            messages\_schema = []
            if 'OpenAI' in globals():
            messages\_schema.append({"role": "system", "content": "You are an expert at extracting structured data from text according to a provided JSON schema."})
            elif 'Anthropic' in globals():
            system\_instruction\_schema = "You are an expert at extracting structured data from text according to a provided JSON schema." \# For Claude 3 system parameter

            messages\_schema.append({"role": "user", "content": instructions\_schema})

            try:
            if 'OpenAI' in globals():
            response\_schema = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages\_schema,
            max\_tokens=400, \# More tokens for complex JSON
            temperature=0.0,
            response\_format={"type": "json\_object"}
            )
            llm\_output\_schema = response\_schema.choices[0].message.content
            elif 'genai' in globals():
            response\_schema = model.generate\_content(
            contents=[{"role": "user", "parts": [instructions\_schema]}],
            generation\_config=genai.types.GenerationConfig(temperature=0.0, max\_output\_tokens=400)
            )
            llm\_output\_schema = response\_schema.text
            elif 'Anthropic' in globals():
            message\_schema = client.messages.create(
            model="claude-3-opus-20240229",
            max\_tokens=400,
            temperature=0.0,
            messages=messages\_schema,
            system=system\_instruction\_schema if 'system\_instruction\_schema' in locals() else None
            )
            llm\_output\_schema = message\_schema.content[0].text

            ```
            print("\nLLM's Schema-Driven JSON Output (raw):")
            print(llm_output_schema)

            parsed_data_schema = json.loads(llm_output_schema)
            print("\nParsed Schema-Driven JSON Data (Python object):")
            print(parsed_data_schema)
            print(f"Product Reviewed: {parsed_data_schema.get('product_reviewed')}")
            print(f"Rating: {parsed_data_schema.get('rating')}/5")
            print(f"Pros: {', '.join(parsed_data_schema.get('pros', []))}")
            ```

            except json.JSONDecodeError as e:
            print(f"\\nError parsing JSON (Schema-driven): {e}")
            print("LLM did not return valid JSON for schema.")
            except Exception as e:
            print(f"An error occurred: {e}")

            ```
            
            ```

          * **Run the script.** Pay close attention to how accurately the LLM fills in the fields and respects the data types and list structures defined in your schema example.

  * **Conclusion of Hands-on Session:**

      * You've successfully implemented powerful techniques for extracting structured data from free-form text using LLMs. By combining explicit format requests, schema definitions, and robust parsing in your Python code, you can now turn raw text into usable data for your applications. This is a game-changer for many automation and data processing tasks.

-----

### **Homework for Hour 4**

  * **Exercise 1: Event Details Extractor:**
      * Create a new Python file `week2_hour4_homework_event.py`.
      * **Your Task:**
          * Take the following event announcement:
            ```text
            "Join us for our 'Annual Tech Meetup' on September 15th, 2024, at the Downtown Innovation Hub, Room 301. Doors open at 6:00 PM, main presentation starts at 6:30 PM. Featuring a keynote by Dr. Anya Sharma on AI Ethics. Register at [techmeetup.com/register](https://techmeetup.com/register) before September 10th to get a free t-shirt!"
            ```
          * Construct a prompt that extracts the following information into a JSON object:
              * `event_name` (string)
              * `date` (string, e.g., "September 15th, 2024")
              * `start_time` (string, e.g., "6:00 PM")
              * `main_speaker` (string)
              * `registration_deadline` (string)
              * `location` (string, combined room and building)
          * Ensure all fields are present (use `null` if not found).
          * Include a `try-except json.JSONDecodeError` block to handle potential invalid JSON output.
      * **Submit:** Your `week2_hour4_homework_event.py` script and its output.
  * **Exercise 2: Recipe Ingredient List (CSV-like):**
      * Write a script that takes a simple recipe instruction (e.g., "To make pancakes, you'll need 1 cup flour, 2 eggs, 1 cup milk, and 2 tbsp sugar.")
      * Prompt the LLM to extract the ingredients and their quantities into a CSV-like string, where each line represents an ingredient.
      * **Example Output Format:**
        ```
        flour,1 cup
        eggs,2
        milk,1 cup
        sugar,2 tbsp
        ```
      * **Submit:** Your script and the output for the example recipe.
  * **Exercise 3: Iterative Refinement for Robustness:**
      * In Task 1 of the hands-on, if the LLM returned invalid JSON, how would you modify your prompt to make it more robust? (e.g., "Ensure the output is strictly valid JSON." or "Wrap the JSON in `json\n...\n`").
      * Describe *one* specific prompt modification you would make and *why* it would improve the reliability of JSON output.

-----

You're mastering a critical skill for building real-world applications with LLMs. Extracting structured data is often the bridge between raw text and actionable insights. Keep pushing forward\!