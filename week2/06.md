Excellent\! You're becoming quite adept at controlling LLM outputs. For **Week 2: Hour 6**, we're going to dive into the exciting world of **Content Generation**. This is where LLMs truly shine as creative partners, helping you brainstorm, draft, and produce original text for various purposes, from marketing copy to creative writing.

-----

### **Week 2: Hour 6 - Creative Content Generation Programmatically**

#### **30% Theory: LLMs as Your Creative Co-Pilot**

  * **Objective:** To understand how LLMs function as generative models for creative tasks, and to learn programmatic techniques for guiding their output in brainstorming, drafting, and producing diverse forms of content.

  * **Generative vs. Transformative:**

      * So far, we've focused on *transforming* existing text (summarization, extraction). Now, we're asking the LLM to *generate entirely new text* based on a prompt.
      * This can range from highly structured output (e.g., a list of business names) to free-form creative writing (e.g., a short story).

  * **Key Techniques for Guiding Creative Generation:**

    1.  **Clear Creative Brief:**

          * **What it is:** Providing the LLM with a "brief" just like you would a human writer.
          * **In code:** Define variables for genre, theme, characters, desired mood, target audience, format, etc., and inject them into your prompt.
          * **Example:** "Write a short, suspenseful story about a robot detective in a cyberpunk city."

    2.  **Controlling Creativity with `temperature` (Revisited):**

          * **Low `temperature` (e.g., 0.1-0.5):** Good for more predictable, structured, or factual generation (e.g., business names, simple marketing taglines). The LLM sticks closer to the most probable words.
          * **High `temperature` (e.g., 0.7-1.0+):** Ideal for brainstorming, diverse ideas, creative writing, poetry, or when you want more surprising and varied outputs. The LLM explores less probable word choices.

    3.  **Specifying Output Format and Constraints:**

          * **What it is:** Even creative tasks benefit from structure.
          * **In code:** Demand bullet points for brainstorming, a specific number of sentences/paragraphs for stories, character limits for social media, or even rhyme schemes for poetry.
          * **Example:** "Generate 5 unique marketing slogans, each under 10 words, for a new coffee shop."

    4.  **Iterative Refinement of Prompts for Creativity:**

          * **What it is:** If the first draft isn't quite right, ask the LLM to revise it based on specific feedback (e.g., "Make it funnier," "Add a plot twist," "Change the ending").
          * **In code:** This involves sending a new message with additional instructions, often referencing the previous LLM output.

    5.  **Persona Assignment:**

          * **What it is:** Telling the LLM to adopt a specific persona (e.g., "Act as a quirky children's author," "You are a serious journalist").
          * **In code:** Use the `system` role (OpenAI/Anthropic) or embed in the initial `user` message (Gemini) to establish this.

#### **70% Hands-on Session: Generating Diverse Content Programmatically**

  * **Objective:** To write Python code that leverages LLMs for various content generation tasks, experimenting with `temperature` and specific creative constraints. We'll continue with your chosen provider.

  * **Step-by-Step Instructions:**

    1.  **Preparation (5 minutes):**

          * Open VS Code in your `applied_llm_course` folder.
          * Create a new file named `week2_hour6_content_generation.py`.
          * Ensure your environment variable for your chosen LLM provider's API key is set in your VS Code terminal.

    2.  **Basic Setup (10 minutes):**

          * Copy the boilerplate for your chosen provider (import statements, API key retrieval, client initialization) into `week2_hour6_content_generation.py`.

    3.  **Task 1: Short Story Generation with Persona and Constraints (15 minutes):**

          * **Goal:** Generate a short, creative story adhering to specific elements and a persona.

          * **Modify `week2_hour6_content_generation.py`:**

            ```python
            # ... (your existing setup code for your chosen provider) ...

            print("\n--- Short Story Generation Example ---")

            genre = "fantasy"
            protagonist = "a wise old wizard"
            setting = "a hidden village nestled in ancient, glowing trees"
            key_element = "a lost magical artifact that controls weather"

            instructions = f"""
            You are a whimsical storyteller. Write a very short story (3-4 sentences) in the {genre} genre.
            The story should feature {protagonist} in {setting},
            and must involve {key_element}.
            Ensure a slightly mysterious and hopeful tone.
            """

            messages = []
            if 'OpenAI' in globals():
                messages.append({"role": "system", "content": "You are a whimsical storyteller."})
            elif 'Anthropic' in globals():
                system_instruction = "You are a whimsical storyteller."

            messages.append({"role": "user", "content": instructions})

            try:
                if 'OpenAI' in globals():
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=messages,
                        max_tokens=150, # Sufficient for 3-4 sentences
                        temperature=0.8 # Higher for creative output
                    )
                    llm_output = response.choices[0].message.content
                elif 'genai' in globals():
                    response = model.generate_content(
                        contents=[{"role": "user", "parts": [instructions]}],
                        generation_config=genai.types.GenerationConfig(temperature=0.8, max_output_tokens=150)
                    )
                    llm_output = response.text
                elif 'Anthropic' in globals():
                    message = client.messages.create(
                        model="claude-3-opus-20240229",
                        max_tokens=150,
                        temperature=0.8,
                        messages=messages,
                        system=system_instruction if 'system_instruction' in locals() else None
                    )
                    llm_output = message.content[0].text

                print("\nLLM's Short Story:")
                print(llm_output)

            except Exception as e:
                print(f"An error occurred: {e}")
            ```

          * **Run the script.** Read the story and see if it met the creative brief.

    4.  **Task 2: Brainstorming Ideas with `temperature` Control (15 minutes):**

          * **Goal:** Generate a list of diverse ideas, explicitly demonstrating the effect of `temperature`.

          * **Add this as a separate section to your script:**

            ```python
            # ... (your existing setup code) ...
            print("\n--- Brainstorming Ideas Example ---")

            product_category = "eco-friendly kitchen gadgets"
            num_ideas = 5

            # --- Attempt 1: Low Temperature (more common/less varied ideas) ---
            print("\nAttempt 1: Low Temperature (0.3) for brainstorming")
            instructions_low_temp = f"""
            Brainstorm exactly {num_ideas} practical product ideas for {product_category}.
            Present them as a numbered list.
            """
            messages_low_temp = []
            if 'OpenAI' in globals(): messages_low_temp.append({"role": "system", "content": "You are a practical product designer."})
            elif 'Anthropic' in globals(): system_instruction_brainstorm = "You are a practical product designer."
            messages_low_temp.append({"role": "user", "content": instructions_low_temp})

            try:
                if 'OpenAI' in globals():
                    response_low = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages_low_temp, max_tokens=200, temperature=0.3)
                    llm_output_low = response_low.choices[0].message.content
                elif 'genai' in globals():
                    response_low = model.generate_content(contents=[{"role": "user", "parts": [instructions_low_temp]}], generation_config=genai.types.GenerationConfig(temperature=0.3, max_output_tokens=200))
                    llm_output_low = response_low.text
                elif 'Anthropic' in globals():
                    message_low = client.messages.create(model="claude-3-opus-20240229", max_tokens=200, temperature=0.3, messages=messages_low_temp, system=system_instruction_brainstorm if 'system_instruction_brainstorm' in locals() else None)
                    llm_output_low = message_low.content[0].text
                print("\nLow Temp Ideas:")
                print(llm_output_low)
            except Exception as e: print(f"Error (Low Temp): {e}")

            # --- Attempt 2: High Temperature (more creative/varied ideas) ---
            print("\nAttempt 2: High Temperature (0.9) for brainstorming")
            instructions_high_temp = f"""
            Brainstorm exactly {num_ideas} highly innovative and unique product ideas for {product_category}.
            Present them as a numbered list.
            """
            messages_high_temp = []
            if 'OpenAI' in globals(): messages_high_temp.append({"role": "system", "content": "You are a futuristic innovator and disruptor."})
            elif 'Anthropic' in globals(): system_instruction_brainstorm = "You are a futuristic innovator and disruptor."
            messages_high_temp.append({"role": "user", "content": instructions_high_temp})

            try:
                if 'OpenAI' in globals():
                    response_high = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages_high_temp, max_tokens=200, temperature=0.9)
                    llm_output_high = response_high.choices[0].message.content
                elif 'genai' in globals():
                    response_high = model.generate_content(contents=[{"role": "user", "parts": [instructions_high_temp]}], generation_config=genai.types.GenerationConfig(temperature=0.9, max_output_tokens=200))
                    llm_output_high = response_high.text
                elif 'Anthropic' in globals():
                    message_high = client.messages.create(model="claude-3-opus-20240229", max_tokens=200, temperature=0.9, messages=messages_high_temp, system=system_instruction_brainstorm if 'system_instruction_brainstorm' in locals() else None)
                    llm_output_high = message_high.content[0].text
                print("\nHigh Temp Ideas:")
                print(llm_output_high)
            except Exception as e: print(f"Error (High Temp): {e}")
            ```

          * **Run the script twice.** Compare the "Low Temp Ideas" and "High Temp Ideas." You should see a noticeable difference in their creativity and originality.

    5.  **Task 3: Marketing Copy in Different Styles (15 minutes):**

          * **Goal:** Generate marketing copy for the same product but in two distinct tones.

          * **Add this as a separate section to your script:**

            ```python
            # ... (your existing setup code) ...
            print("\n--- Marketing Copy Style Example ---")

            product_name = "Zenith Smart Mug"
            product_feature = "keeps your drink at the perfect temperature for hours"

            # --- Style 1: Enthusiastic and Modern ---
            print("\nStyle 1: Enthusiastic and Modern Marketing Copy")
            instructions_style1 = f"""
            Write a short (2-3 sentences) marketing blurb for {product_name}, which {product_feature}.
            Use an enthusiastic, modern, and slightly informal tone. Include one relevant hashtag.
            """
            messages_style1 = []
            if 'OpenAI' in globals(): messages_style1.append({"role": "system", "content": "You are a hip social media marketer."})
            elif 'Anthropic' in globals(): system_instruction_marketing = "You are a hip social media marketer."
            messages_style1.append({"role": "user", "content": instructions_style1})

            try:
                if 'OpenAI' in globals():
                    response_style1 = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages_style1, max_tokens=100, temperature=0.7)
                    llm_output_style1 = response_style1.choices[0].message.content
                elif 'genai' in globals():
                    response_style1 = model.generate_content(contents=[{"role": "user", "parts": [instructions_style1]}], generation_config=genai.types.GenerationConfig(temperature=0.7, max_output_tokens=100))
                    llm_output_style1 = response_style1.text
                elif 'Anthropic' in globals():
                    message_style1 = client.messages.create(model="claude-3-opus-20240229", max_tokens=100, temperature=0.7, messages=messages_style1, system=system_instruction_marketing if 'system_instruction_marketing' in locals() else None)
                    llm_output_style1 = message_style1.content[0].text
                print(llm_output_style1)
            except Exception as e: print(f"Error (Style 1): {e}")

            # --- Style 2: Elegant and Luxurious ---
            print("\nStyle 2: Elegant and Luxurious Marketing Copy")
            instructions_style2 = f"""
            Write a short (2-3 sentences) marketing blurb for {product_name}, which {product_feature}.
            Use an elegant, luxurious, and sophisticated tone. Focus on refinement and convenience.
            """
            messages_style2 = []
            if 'OpenAI' in globals(): messages_style2.append({"role": "system", "content": "You are a luxury brand copywriter."})
            elif 'Anthropic' in globals(): system_instruction_marketing = "You are a luxury brand copywriter."
            messages_style2.append({"role": "user", "content": instructions_style2})

            try:
                if 'OpenAI' in globals():
                    response_style2 = client.chat.completions.create(model="gpt-3.5-turbo", messages=messages_style2, max_tokens=100, temperature=0.7)
                    llm_output_style2 = response_style2.choices[0].message.content
                elif 'genai' in globals():
                    response_style2 = model.generate_content(contents=[{"role": "user", "parts": [instructions_style2]}], generation_config=genai.types.GenerationConfig(temperature=0.7, max_output_tokens=100))
                    llm_output_style2 = response_style2.text
                elif 'Anthropic' in globals():
                    message_style2 = client.messages.create(model="claude-3-opus-20240229", max_tokens=100, temperature=0.7, messages=messages_style2, system=system_instruction_marketing if 'system_instruction_marketing' in locals() else None)
                    llm_output_style2 = message_style2.content[0].text
                print(llm_output_style2)
            except Exception as e: print(f"Error (Style 2): {e}")
            ```

          * **Run the script.** Compare the two marketing blurbs. Notice how the LLM adapts its language, vocabulary, and sentence structure to match the requested style.

  * **Conclusion of Hands-on Session:**

      * You've successfully programmed LLMs to generate diverse and creative content. By setting clear briefs, adjusting `temperature`, and enforcing stylistic constraints, you've turned a powerful AI into your personal content creation engine. This skill is invaluable for any application requiring dynamic and engaging text.

-----

### **Homework for Hour 6**

  * **Exercise 1: Dynamic Children's Story Generator:**
      * Create a new Python file `week2_hour6_homework_story.py`.
      * Ask the user (using `input()`) for:
        1.  A main character (e.g., "a brave squirrel")
        2.  A magical item (e.g., "a shimmering acorn")
        3.  A simple moral for the story (e.g., "sharing is caring")
      * Construct a prompt for your chosen LLM (using appropriate persona and `temperature`) to write a very short (3-5 sentences) children's story incorporating these elements and ending with the moral.
      * **Submit:** Your `week2_hour6_homework_story.py` script and an example output from running it.
  * **Exercise 2: Social Media Post Variations:**
      * Pick a fictional event (e.g., "Grand Opening of 'The Cozy Bookstore'" or "Local Charity Run").
      * Write a script that generates three different social media posts for this event, each with a distinct tone:
        1.  Very enthusiastic/excited.
        2.  Calm/informative.
        3.  Humorous/playful.
      * Include relevant emojis and hashtags for each.
      * **Submit:** Your script and the three different social media posts.
  * **Exercise 3: Brainstorming for Constraints:**
      * Imagine you need to generate 10 unique names for a new mobile app that helps people meditate.
      * Write a prompt and code that achieves this using a high `temperature`.
      * Now, *without changing the `temperature`*, refine your prompt to add a new constraint: each name must be exactly two words long, and at least one word must relate to "peace" or "calm."
      * **Submit:** Both the initial (high temp) list of names, the refined prompt, and the new list of names that adhere to the two-word and theme constraints. Briefly explain how the refined prompt guided the LLM.

-----

You're mastering the creative potential of LLMs through code. This is a highly sought-after skill in many industries. Keep up the excellent work\!