Let's adapt **Week 2: Hour 1** to include options for Google Gemini and Anthropic's Claude. We'll present the OpenAI method as the primary example, but clearly show how to get started with Gemini and Claude as alternatives, focusing on the core concept of an API call.

This will make the setup a bit longer, but it's a critical investment. I'll make sure to note that you only need to pick *one* provider to start with for the immediate hands-on, but the instructions are there for others.

-----

### **Week 2: Hour 1 - Setting Up Your Lab & Your First LLM API Call (Multi-Provider Options)**

#### **30% Theory: The API Gateway to LLMs & Environment Setup**

  * **Objective:** To understand what an API is in the context of LLMs, why we use them, and to guide you through setting up your local development environment for Python, with options for popular LLM providers.

  * **What is an API? (Application Programming Interface):**

      * Think of an API as a menu in a restaurant. You don't go into the kitchen to cook your meal; you look at the menu, tell the waiter what you want (e.g., "I'd like a grilled salmon"), and the kitchen prepares it and brings it to you.
      * Similarly, an LLM API is a set of rules and protocols that allows your computer program to "talk" to a powerful LLM running on someone else's servers (like OpenAI's, Google's, or Anthropic's).
      * You send a "request" (your prompt) to the API, and the API sends back a "response" (the LLM's generated text).
      * **Why APIs?** They give you access to incredibly powerful models without needing to run them on your own computer (which requires immense computing power and data).

  * **Key Components of Your Development Environment:**

      * **Python:** The programming language we'll use. You should have installed this in Hour 10's homework.
      * **Code Editor (VS Code):** Where you'll write and organize your Python code. Also from homework.
      * **Terminal/Command Prompt:** Where you'll run your Python programs.
      * **`pip` (Python's Package Installer):** Used to install Python libraries (like the ones for interacting with LLM APIs).
      * **API Key:** A unique secret code provided by LLM service providers (like OpenAI, Google, Anthropic). It authenticates your requests and tracks your usage. **Treat it like your password; never share it publicly.**

  * **How LLM APIs Work (Simplified):**

      * Your Python code sends a request to the LLM provider's servers.
      * This request includes your API key, the model you want to use (e.g., `gpt-3.5-turbo` for OpenAI, `gemini-pro` for Google, `claude-3-opus-20240229` for Anthropic), and your prompt.
      * The LLM processes your prompt.
      * The API sends back the LLM's response to your Python code.

#### **70% Hands-on Session: Setting Up & Your First Programmatic Prompt (Choose Your Adventure\!)**

  * **Objective:** To get your development environment ready, install the necessary Python library for *your chosen provider*, obtain an API key, and send your very first prompt to an LLM using Python code.

  * **Step-by-Step Instructions:**

    1.  **Verify Python and VS Code Installation (10 minutes):**

          * **Open your Terminal/Command Prompt:**
              * On Windows: Search for "Command Prompt" or "PowerShell".
              * On macOS: Search for "Terminal".
              * On Linux: Open your preferred terminal emulator.
          * **Verify Python:** Type `python --version` and press Enter. You should see `Python 3.x.x` (where x.x is your version). If not, revisit Week 1 Homework 1.
          * **Verify `pip`:** Type `pip --version` and press Enter. You should see `pip x.x.x`.
          * **Open VS Code:** Launch VS Code.

    2.  **Create a Project Folder (5 minutes):**

          * In VS Code, go to `File > Open Folder...` (or `Open...` on macOS).
          * Create a new folder on your desktop or in your documents, named `applied_llm_course`.
          * Select this folder and click "Open Folder". This will be our main workspace for the course.
          * Inside VS Code's "Explorer" pane (left sidebar), click the "New File" icon and name it `week2_hour1_llm_call.py`. This is where we'll write our code.

    -----

    ### **Choose ONE LLM Provider to Start With (OpenAI is Recommended for the first run):**

    *You only need to complete the steps for ONE provider to get started. You can explore others later.*

    -----

    ### **Option 1: OpenAI Setup**

    3a. **Install the OpenAI Python Library (5 minutes):**

    ````
      * **Open a new Terminal in VS Code:** Go to `Terminal > New Terminal` in the VS Code menu.
      * In the VS Code terminal, type:
        ```bash
        pip install openai
        ```
      * Press Enter.
    ````

    4a. **Get Your OpenAI API Key (10 minutes):**

    ```
      * Go to **[https://platform.openai.com/signup](https://platform.openai.com/signup)**
      * Sign up for an account if you don't have one. New accounts usually receive free credits (often $5.00) that last for a few months.
      * Once logged in, go to **[https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)**
      * Click "Create new secret key".
      * **Copy this key IMMEDIATELY and save it securely.** You will *not* be able to see it again.
      * **Do NOT share this key publicly or embed it directly in your code.**
    ```

    5a. **Set Your OpenAI API Key as an Environment Variable (5 minutes):**

    ````
      * **For Windows (PowerShell):** In your VS Code terminal (or PowerShell):
        ```bash
        $env:OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"
        ```
      * **For macOS/Linux (Bash/Zsh):** In your VS Code terminal:
        ```bash
        export OPENAI_API_KEY="YOUR_OPENAI_API_KEY_HERE"
        ```
      * **Verify:** Type `echo $OPENAI_API_KEY` (macOS/Linux) or `echo $env:OPENAI_API_KEY` (Windows). You should see your key printed.
    ````

    6a. **Your First OpenAI Python LLM API Call (15 minutes):**

    ````
      * In your `week2_hour1_llm_call.py` file, add the following code:

        ```python
        # week2_hour1_llm_call.py - OpenAI Example

        import os
        from openai import OpenAI

        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            print("Error: OPENAI_API_KEY environment variable not set.")
            exit()

        client = OpenAI(api_key=api_key)
        user_prompt = "Tell me a very short, cheerful fact about sloths."
        print(f"Sending prompt to OpenAI LLM: '{user_prompt}'")

        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": user_prompt}],
                max_tokens=50
            )
            llm_response_content = response.choices[0].message.content
            print("\nOpenAI's Response:")
            print(llm_response_content)

        except Exception as e:
            print(f"An error occurred with OpenAI: {e}")
            print("Make sure your API key is correct and you have an active internet connection.")
            print("Check your OpenAI dashboard for usage limits or billing issues.")
        ```
      * **Save the file.**
      * **Run:** In your VS Code terminal, type `python week2_hour1_llm_call.py` and press Enter.
    ````

    -----

    ### **Option 2: Google Gemini Setup**

    3b. **Install the Google Generative AI Python Library (5 minutes):**

    ````
      * **Open a new Terminal in VS Code.**
      * In the VS Code terminal, type:
        ```bash
        pip install google-generativeai
        ```
      * Press Enter.
    ````

    4b. **Get Your Google Gemini API Key (10 minutes):**

    ```
      * Go to **[https://makersuite.google.com/](https://makersuite.google.com/)**
      * Sign in with your Google account.
      * Navigate to the "Get API key" section on the left sidebar or directly go to **[https://makersuite.google.com/app/apikey](https://makersuite.google.com/app/apikey)**
      * Click "Create API key in new project".
      * **Copy this key IMMEDIATELY and save it securely.**
      * **Do NOT share this key publicly or embed it directly in your code.**
    ```

    5b. **Set Your Google Gemini API Key as an Environment Variable (5 minutes):**

    ````
      * **For Windows (PowerShell):** In your VS Code terminal:
        ```bash
        $env:GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
        ```
      * **For macOS/Linux (Bash/Zsh):** In your VS Code terminal:
        ```bash
        export GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
        ```
      * **Verify:** Type `echo $GOOGLE_API_KEY` (macOS/Linux) or `echo $env:GOOGLE_API_KEY` (Windows).
    ````

    6b. **Your First Google Gemini Python LLM API Call (15 minutes):**

    ````
      * In your `week2_hour1_llm_call.py` file, add the following code (you can comment out the OpenAI code if you wish):

        ```python
        # week2_hour1_llm_call.py - Google Gemini Example

        import os
        import google.generativeai as genai

        api_key = os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            print("Error: GOOGLE_API_KEY environment variable not set.")
            exit()

        # Configure the Google Generative AI client
        genai.configure(api_key=api_key)

        # Choose the model (gemini-pro is suitable for text)
        model = genai.GenerativeModel('gemini-pro')

        user_prompt = "Tell me a very short, cheerful fact about sloths."
        print(f"Sending prompt to Google Gemini LLM: '{user_prompt}'")

        try:
            # Generate content
            response = model.generate_content(
                contents=[user_prompt]
            )
            llm_response_content = response.text # Gemini's response is in .text attribute
            print("\nGoogle Gemini's Response:")
            print(llm_response_content)

        except Exception as e:
            print(f"An error occurred with Google Gemini: {e}")
            print("Make sure your API key is correct and you have an active internet connection.")
            print("Check your Google Cloud console for usage limits or billing issues.")
        ```
      * **Save the file.**
      * **Run:** In your VS Code terminal, type `python week2_hour1_llm_call.py` and press Enter.
    ````

    -----

    ### **Option 3: Anthropic Claude Setup**

    3c. **Install the Anthropic Python Library (5 minutes):**

    ````
      * **Open a new Terminal in VS Code.**
      * In the VS Code terminal, type:
        ```bash
        pip install anthropic
        ```
      * Press Enter.
    ````

    4c. **Get Your Anthropic Claude API Key (10 minutes):**

    ```
      * Go to **[https://console.anthropic.com/signup](https://console.anthropic.com/signup)**
      * Sign up for an account. You'll likely need to add a payment method to access API keys, even for initial free usage, but check their current free tier policies.
      * Once logged in, go to `API Keys` section on the left sidebar.
      * Click "Create Key".
      * **Copy this key IMMEDIATELY and save it securely.**
      * **Do NOT share this key publicly or embed it directly in your code.**
    ```

    5c. **Set Your Anthropic Claude API Key as an Environment Variable (5 minutes):**

    ````
      * **For Windows (PowerShell):** In your VS Code terminal:
        ```bash
        $env:ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY_HERE"
        ```
      * **For macOS/Linux (Bash/Zsh):** In your VS Code terminal:
        ```bash
        export ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY_HERE"
        ```
      * **Verify:** Type `echo $ANTHROPIC_API_KEY` (macOS/Linux) or `echo $env:ANTHROPIC_API_KEY` (Windows).
    ````

    6c. **Your First Anthropic Claude Python LLM API Call (15 minutes):**

    ````
      * In your `week2_hour1_llm_call.py` file, add the following code (comment out previous examples):

        ```python
        # week2_hour1_llm_call.py - Anthropic Claude Example

        import os
        from anthropic import Anthropic

        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            print("Error: ANTHROPIC_API_KEY environment variable not set.")
            exit()

        client = Anthropic(api_key=api_key)

        user_prompt = "Tell me a very short, cheerful fact about sloths."
        print(f"Sending prompt to Anthropic Claude LLM: '{user_prompt}'")

        try:
            message = client.messages.create(
                model="claude-3-opus-20240229", # Or "claude-3-sonnet-20240229" for cheaper model
                max_tokens=50,
                messages=[
                    {"role": "user", "content": user_prompt}
                ]
            )
            llm_response_content = message.content[0].text
            print("\nAnthropic Claude's Response:")
            print(llm_response_content)

        except Exception as e:
            print(f"An error occurred with Anthropic Claude: {e}")
            print("Make sure your API key is correct and you have an active internet connection.")
            print("Check your Anthropic console for usage limits or billing issues.")
        ```
      * **Save the file.**
      * **Run:** In your VS Code terminal, type `python week2_hour1_llm_call.py` and press Enter.
    ````

    -----

  * **Conclusion of Hands-on Session:**

      * You've successfully navigated the initial setup for interacting with LLMs programmatically. Whichever provider you chose, you've made your first Python API call to a powerful AI model. This is a crucial step towards building real LLM applications\!

-----

### **Homework for Hour 1**

  * **Exercise 1: Modify Your Program (for your chosen provider):**
      * Change the `user_prompt` in your `week2_hour1_llm_call.py` script to ask a different, more complex question (e.g., "Write a 2-sentence summary of the main points of the theory of relativity").
      * Also, adjust the `max_tokens` (or equivalent parameter) to allow for a slightly longer response (e.g., 70-100 tokens).
      * Run the script again and observe the new output.
      * **Submit:** The modified `user_prompt` string and the LLM's new response.
  * **Exercise 2: Explain Your Code:**
      * In your own words, write a short paragraph (3-5 sentences) explaining what each major section of *your specific provider's* `week2_hour1_llm_call.py` script does (e.g., importing libraries, getting the API key, initializing the client, making the call, extracting and printing the response).
  * **Exercise 3: API Key Security (Revisited):**
      * Why is using environment variables for API keys a crucial security practice, especially when you might share your code with others (e.g., on GitHub)?
      * Write 2-3 sentences explaining this, connecting it to the concept of sensitive information.

-----

This revised Hour 1 should give you a robust start with programmatic LLM interactions, offering the flexibility to choose your preferred provider while learning the universal principles of API communication.