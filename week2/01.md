### **Week 2: Hour 1 - Setting Up Your Lab & Your First LLM API Call (Multi-Provider Options)**

#### **The API Gateway to LLMs & Environment Setup**

**Objective:** To understand what an API is in the context of LLMs, why we use them, and to guide you through setting up your local development environment for Python, with options for popular LLM providers.

**What is an API? (Application Programming Interface):**

* Think of an API as a menu in a restaurant. You don't go into the kitchen to cook your meal; you look at the menu, tell the waiter what you want and the kitchen prepares it and brings it to you.
* Similarly, an LLM API is a set of rules and protocols that allows your computer program to "talk" to a powerful LLM running on someone else's servers (like OpenAI's, Google's, or Anthropic's).
* You send a "request" (your prompt) to the API, and the API sends back a "response" (the LLM's generated text).
* **Why APIs?** They give you access to incredibly powerful models without needing to run them on your own computer (which requires immense computing power and data).

**Key Components of Your Development Environment:**

  * **Python:** The programming language we'll use. You should have installed this in Hour 10's homework.
  * **Code Editor (VS Code):** Where you'll write and organize your Python code. Also from homework.
  * **Terminal/Command Prompt:** Where you'll run your Python programs.
  * **`pip` (Python's Package Installer):** Used to install Python libraries (like the ones for interacting with LLM APIs).
  * **API Key:** A unique secret code provided by LLM service providers (like OpenAI, Google, Anthropic). It authenticates your requests and tracks your usage. **Treat it like your password; never share it publicly.**

**How LLM APIs Work (Simplified):**
  * Your Python code sends a request to the LLM provider's servers.
  * This request includes your API key, the model you want to use (e.g., `gpt-3.5-turbo` for OpenAI, `gemini-pro` for Google, `claude-3-opus-20240229` for Anthropic), and your prompt.
  * The LLM processes your prompt.
  * The API sends back the LLM's response to your Python code.

## Hands-on Session: Setting Up & Your First Programmatic Prompt

**Objective:** 
- To get your development environment ready, 
- install the necessary Python library for *your chosen provider*, 
- obtain an API key, 
- and send your very first prompt to an LLM using Python code.

## Step-by-Step Instructions:

- Verify Python
  - Try, `python --version`. You should see `Python 3.x.x` (where x.x is your version). If not, revisit install python.
  - Try `pip --version`. You should see `pip x.x.x`.

## Choose ONE LLM Provider to Start With
*You only need to complete the steps for ONE provider to get started. You can explore others later.*

### **Option 1: OpenAI Setup**
- Install the OpenAI Python Library
  ```bash
  pip install openai
  ```
- Get Your OpenAI API Key
  - [https://platform.openai.com/signup](https://platform.openai.com/signup) Sign up for an account if you don't have one. 
  - Once logged in, go to [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
  - Generate new secret key
  - Copy this key **IMMEDIATELY and save it securely** You will *not* be able to see it again.
  - Do NOT share this key publicly or embed it directly in your code.**
    

- Set Your OpenAI API Key as an Environment Variable:
  - For Windows (PowerShell)
    ```bash
     $env:OPENAI_API_KEY="YOUR_KEY"
    ```
  - For macOS/Linux (Bash/Zsh)
    ```bash
     export OPENAI_API_KEY="YOUR_KEY"
    ```
  - Verify: Type `echo $OPENAI_API_KEY` (macOS/Linux) or `echo $env:OPENAI_API_KEY` (Windows). You should see your key printed.
    
## Your First OpenAI Python LLM API Call

```python
# week2_hour1_llm_call.py - OpenAI Example
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",
    input="Explain how AI works in a few words"
)

print(response.output_text)
```
## Save the file and Run
type `python week2_hour1_llm_call.py`

-----

### **Option 2: Google Gemini Setup**

- Install the Google Generative AI Python Library

```bash
  pip install -q -U google-genai
```

- Get Your [Google Gemini API Key](https://aistudio.google.com/api-keys) 


- Set Your Google Gemini API Key as an Environment Variable **GOOGLE_API_KEY**

  For Windows (PowerShell):** In your VS Code terminal:
  ```bash
  $env:GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
  ```
  For macOS/Linux (Bash/Zsh)
  ```bash
  export GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY_HERE"
  ```
  Verify: Type `echo $GOOGLE_API_KEY` (macOS/Linux) or `echo $env:GOOGLE_API_KEY` (Windows).

## Your First Google Gemini Python LLM API Call

```python
# week2_hour1_llm_call_gemini.py - Google Gemini Example
from google import genai

client = genai.Client()

response = client.models.generate_content(
    model="gemini-2.5-flash",
    contents="Explain how AI works in a few words",
)

print(response.text)
```
* Save the file & Run `python week2_hour1_llm_call_gemini.py` and press Enter.

## Option 3: Anthropic Claude Setup
- Install the Anthropic Python Library
  ```bash
  pip install anthropic
  ```

- Get Your Anthropic Claude API Key: 
  Go to Anthropic site and sign up and create the aPI key. 

- Set Your Anthropic Claude API Key as an Environment Variable **ANTHROPIC_API_KEY**

## Your First Anthropic Claude Python LLM API Call 
```python
# week2_hour1_llm_call_claude.py - Anthropic Claude Example

import anthropic

client = anthropic.Anthropic()

message = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=1000,
    messages=[
        {
            "role": "user",
            "content": "Explain how AI works in a few words"
        }
    ]
)
print(message.content)
```
- Save the file and run

### **Homework for Hour 1**

Modify Your Program to read the prompt from user
