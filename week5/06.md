The core `gpt-4o` conversational bot you built is a great foundation. We'll now enhance it by integrating and showcasing models from other major players like **Google's Gemini** and **Anthropic's Claude**.

-----

### Day 5: Enhanced Multimodal Conversational Bot ðŸ¤–

We'll modify our script from Day 4 to allow you to select a different LLM and then demonstrate a capability unique to each. This will create a more powerful and versatile application.

#### **Hands-on Session: Code Refactoring**

First, you'll need to install the necessary SDKs and set up the new API keys.

1.  **Install the SDKs:**

    ```bash
    # For Google Gemini
    pip install google-generativeai

    # For Anthropic Claude
    pip install anthropic
    ```

2.  **Get API Keys:**

      * **Gemini:** Go to [Google AI Studio](https://ai.google.dev/) and click on "Get API key."
      * **Claude:** Navigate to the [Anthropic console](https://www.google.com/search?q=https://console.anthropic.com/home) and find the "API Keys" section. You'll need to add a credit card to get started, but usage is pay-as-you-go.

3.  **Enhance the Conversational Loop:** We'll create a function for each LLM and then let the user choose which one to use. This makes the code modular and easy to manage.

    ```python
    import openai
    import os
    import pyaudio
    import wave
    import speech_recognition as sr
    from anthropic import Anthropic
    from google.generativeai import GenerativeModel

    # Initialize Clients
    openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
    gemini_client = GenerativeModel(model_name="gemini-1.5-pro-latest")

    recognizer = sr.Recognizer()

    def get_openai_response(prompt):
        # Good for general-purpose tasks, creative content, and tool use
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    def get_claude_response(prompt):
        # Excellent for long-context reasoning and safe, ethical responses
        response = claude_client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text

    def get_gemini_response(prompt):
        # Great for multimodal tasks, coding, and logical reasoning
        response = gemini_client.generate_content(prompt)
        return response.text
        
    def get_llm_response(prompt, model_choice):
        if model_choice == "openai":
            return get_openai_response(prompt)
        elif model_choice == "claude":
            return get_claude_response(prompt)
        elif model_choice == "gemini":
            return get_gemini_response(prompt)
        else:
            return "Invalid model choice. Please select 'openai', 'claude', or 'gemini'."

    # (Keep the rest of your original script - record_audio, transcribe_audio, synthesize_speech, play_audio)

    # Main conversational loop
    if __name__ == "__main__":
        print("Starting voice chatbot.")
        model_choice = input("Choose your LLM (openai, claude, gemini): ").lower()
        
        while True:
            # 1. Record user audio
            input_audio_file = record_audio(duration=5)
            
            # 2. Transcribe
            user_text = transcribe_audio(input_audio_file)
            print(f"User: {user_text}")
            
            if user_text.lower().strip() in ["stop", "exit", "quit"]:
                print("Goodbye!")
                break
            
            # 3. Get LLM response
            llm_text = get_llm_response(user_text, model_choice)
            print(f"AI ({model_choice}): {llm_text}")
            
            # 4. Synthesize and play response
            response_audio_file = synthesize_speech(llm_text)
            play_audio(response_audio_file)
    ```

#### **How to Demo Different Capabilities**

By using this new architecture, you can design prompts that highlight each LLM's strengths. Here are some examples:

  * **For GPT-4o:** Ask for a creative story, a poem, or to generate code for a simple function. Its strength is its well-rounded, creative ability.
  * **For Claude:** Paste a very long block of text (e.g., a few paragraphs from a Wikipedia article) and ask it to summarize the key points or analyze it for ethical considerations. Claude's large context window and "Constitutional AI" make it a top performer for this.
  * **For Gemini:** Ask it a complex reasoning question that requires logical deduction or provide a mix of information, like "I have a text file of sales data and an image of a company's stock chart. Based on the text, can you explain the trend in the image?" Gemini's native multimodal architecture makes it excellent at connecting disparate data points.

This enhanced script gives you a sandbox to truly understand the nuance and specialization of each LLM beyond a simple chatbot.

-----
