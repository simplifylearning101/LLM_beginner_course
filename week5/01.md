Let's begin with the first three days of our journey into multimodal applications. We'll start with images, then move to audio, and finally, bring both together with video.

-----

### Day 1: Image Understanding & Generation

The first step in working with other data types is enabling your agent to "see" and interpret images. We will focus on two key tasks: **Image Captioning** and **Visual Question Answering (VQA)**. We'll use a powerful multimodal model like `gpt-4o` for this.

#### **Hands-on Session: Building a Visual Agent**

1.  **Preparation:**

      * Ensure you have the `openai` library installed and your API key is configured.
      * You'll need an image file to work with. You can use any image you have or find one online. We will use a local image file and encode it in Base64 for the API call.

2.  **Code: Visual Question Answering (VQA)**

      * The key to working with images in the OpenAI API is to encode the image as a **Base64** string. This allows the image data to be sent as part of the JSON payload.
      * Let's create a simple Python script to ask a question about a local image.

    <!-- end list -->

    ```python
    import base64
    import openai
    import os

    # Your OpenAI API key
    openai.api_key = os.getenv("OPENAI_API_KEY")

    # Function to encode a local image file to Base64
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    # Path to your local image file
    image_path = "path/to/your/image.jpg"

    # Encode the image
    base64_image = encode_image(image_path)

    # Make the API call
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "What is in this image?"},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=300
        )
        print(response.choices[0].message.content)
    except Exception as e:
        print(f"An error occurred: {e}")
    ```

#### **Homework:**

  * Modify the script to perform **Visual Question Answering (VQA)**. Instead of a general question like "What is in this image?", ask a specific question, like "What is the dog doing in this picture?" or "How many people are in this room?".

-----

