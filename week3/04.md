### **Week 3: Hour 4 - Building an Advanced Tool-Using Agent**

#### **30% Theory: The Agentic Loop in Practice** ⚙️

This hour builds directly on our introduction to agents from Hour 2. We'll move from a simple, hardcoded tool to a more robust, extensible system capable of handling complex interactions.

  * **The Power of Tool Descriptions:** The most critical part of an agent is the prompt that describes its tools. A great description isn't just a name; it includes:

      * A clear, concise purpose.
      * Exact input parameters with their data types.
      * Precise output format.
      * An example of correct usage.
        The LLM relies solely on this information to decide whether and how to use a tool.

  * **Robust Parsing:** Our simple `if` check from Hour 2 was a great start, but a real-world agent needs a more reliable way to parse the LLM's output. Using regular expressions or parsing libraries is essential to extract tool names and arguments accurately, making your agent less prone to errors.

  * **From Simple to Sophisticated Tools:** The tools an agent uses are just functions that you, the developer, write. While they can be as simple as adding two numbers, they can also be:

      * **API Wrappers:** Functions that call external APIs (e.g., a real-time weather API, a stock market API).
      * **Database Queries:** Functions that retrieve information from a SQL or NoSQL database.
      * **File I/O:** Functions that read from or write to a document.

  * **The Agentic Loop, Re-engineered:** The loop remains the same (`Act` -\> `Observe` -\> `Loop`), but our implementation will become more robust, handling multiple tool calls and more complex outputs.

-----

#### **70% Hands-on Session: Building a Multi-Tool Agent**

  * **Objective:** To build a functional LLM agent that can use two distinct, more complex tools to answer a user's query.

  * **Step-by-Step Instructions:**

    1.  **Preparation:**

          * Open VS Code and create a new file: `week3_hour4_advanced_agent.py`.
          * Copy your robust LLM setup from Week 2, Hour 9 (imports, API key, `get_llm_response_robust`).
          * Add `import json` and `import re` at the top of your script.

    2.  **Task 1: Define a More Complex Toolset:**

          * **Goal:** Create two new Python functions that simulate more realistic external API calls and have well-defined inputs and outputs.

          * **Add the following code to your script:**

            ```python
            # ... (your existing setup code and get_llm_response_robust function) ...

            # --- Task 1: Define More Sophisticated Tools ---
            def get_stock_price(ticker: str) -> str:
                """
                Returns the simulated stock price for a given ticker symbol.
                Example: get_stock_price(ticker='GOOG')
                """
                if ticker.upper() == 'AAPL':
                    return json.dumps({"ticker": "AAPL", "price": 175.50})
                elif ticker.upper() == 'GOOG':
                    return json.dumps({"ticker": "GOOG", "price": 145.20})
                elif ticker.upper() == 'MSFT':
                    return json.dumps({"ticker": "MSFT", "price": 410.85})
                return json.dumps({"error": f"Stock data not found for {ticker.upper()}"})

            def perform_calculation(expression: str) -> str:
                """
                Performs a basic mathematical calculation on an expression.
                Example: perform_calculation(expression='5 * 10 - 2')
                """
                try:
                    result = eval(expression)
                    return f"The result of {expression} is {result}."
                except Exception as e:
                    return f"Error performing calculation: {e}"

            # Dictionary to map tool names to functions
            TOOLS = {
                "get_stock_price": get_stock_price,
                "perform_calculation": perform_calculation,
            }
            ```

    3.  **Task 2: Craft a Robust Agentic Prompt:**

          * **Goal:** Write a detailed prompt that instructs the LLM on its role, the tools it has, and a more specific, parsable output format for calling tools.

          * **Add this code:**

            ```python
            # ... (code from Task 1) ...

            # The core agentic prompt
            AGENT_PROMPT = """
            You are a helpful assistant with access to the following tools:

            Name: get_stock_price
            Description: Use this to get the latest stock price for a ticker symbol (AAPL, GOOG, or MSFT).
            Parameters:
            - ticker (string, required): The stock ticker symbol.

            Name: perform_calculation
            Description: Use this to perform a simple mathematical calculation.
            Parameters:
            - expression (string, required): The mathematical expression to evaluate.

            To use a tool, you must follow this exact, single-line format:
            <tool_call> TOOL_NAME="[tool_name]" PARAMETERS="{[param_name]":"[param_value]", ...}" </tool_call>

            If you have all the information to answer a question directly, or once you have used a tool and have the result, provide a final answer in natural language.
            If the user asks for information not covered by your tools, say so.
            """
            ```

    4.  **Task 3: Implement the Advanced Agentic Loop:**

          * **Goal:** Write a `while` loop that uses regular expressions to reliably parse the LLM's tool-call output and execute the corresponding function.

          * **Add this code to the end of your script:**

            ```python
            # ... (code from Task 1 and 2) ...

            print("\n--- Advanced Multi-Tool Agent ---")
            print("Ask me for a stock price (AAPL, GOOG, MSFT) or to perform a calculation.")
            print("Type 'quit' or 'exit' to end.")

            while True:
                user_input = input("\nYou: ").strip()
                if user_input.lower() in ["quit", "exit"]:
                    print("Goodbye!")
                    break

                messages = [{"role": "user", "content": AGENT_PROMPT + f"\nUser Question: {user_input}"}]
                if 'OpenAI' in globals():
                    messages.insert(0, {"role": "system", "content": "You are a helpful assistant with access to tools."})

                try:
                    raw_response = get_llm_response_robust(messages, LLM_MODEL, temp=0.0, max_response_tokens=150)
                    print(f"\nDEBUG: Raw LLM Output -> {raw_response}")

                    tool_call_match = re.search(r'<tool_call>.*</tool_call>', raw_response)
                    
                    if tool_call_match:
                        print("DEBUG: Agent decided to use a tool.")
                        tool_call_str = tool_call_match.group(0)

                        # Extract tool name and parameters using regex
                        tool_name_match = re.search(r'TOOL_NAME="([^"]+)"', tool_call_str)
                        params_match = re.search(r'PARAMETERS="([^"]+)"', tool_call_str)

                        if tool_name_match and params_match:
                            tool_name = tool_name_match.group(1)
                            params_str = params_match.group(1).replace("'", '"')
                            
                            try:
                                params = json.loads(params_str)
                                print(f"DEBUG: Calling tool '{tool_name}' with parameters {params}")
                                
                                # Call the tool function
                                if tool_name in TOOLS:
                                    tool_result = TOOLS[tool_name](**params)
                                else:
                                    tool_result = f"Error: Tool '{tool_name}' not found."

                                # Feed the result back to the LLM
                                final_answer_prompt = f"""
                                Based on this tool's result, answer the user's original question: '{user_input}'
                                Tool Result: {tool_result}
                                """
                                messages_final_answer = [{"role": "user", "content": AGENT_PROMPT + final_answer_prompt}]
                                if 'OpenAI' in globals():
                                    messages_final_answer.insert(0, {"role": "system", "content": "You are a helpful assistant with access to tools."})
                                
                                final_answer = get_llm_response_robust(messages_final_answer, LLM_MODEL, temp=0.0, max_response_tokens=150)
                                print("Assistant:", final_answer)
                            except json.JSONDecodeError:
                                print("Assistant: An error occurred parsing the tool parameters. Please try again.")
                            except Exception as e:
                                print(f"Assistant: An unexpected error occurred during tool execution: {e}")
                        else:
                            print("Assistant: I'm sorry, I couldn't understand the tool call. Please try again.")
                    else:
                        print("Assistant:", raw_response)
                except Exception as e:
                    print(f"Assistant: An unexpected error occurred: {e}")
            ```

          * **Run the script.** Test it with queries like:

              * "What's the price of GOOG?"
              * "What is 10 times 5 plus 2?"
              * "What is the capital of Canada?" (This should be answered directly or fail gracefully).

  * **Conclusion:** You've built a more sophisticated LLM agent that can intelligently route a user's request to the correct tool, execute it, and then synthesize the result into a final answer. This is a powerful pattern for building complex, task-oriented applications.

#### **Homework for Hour 4**

  * **Exercise 1: Add a "Fact-Checker" Tool.**
      * Add a new function to your agent called `fact_check(statement: str)`. This function should return a hardcoded response indicating whether the statement is true or false. For example, if the statement is "The Earth is flat," it should return "False, the Earth is a sphere."
      * Update the `AGENT_PROMPT` to include a description of this new tool.
      * Test your agent with a few true and false statements, observing how it uses your new tool to respond.
      * **Submit:** Your modified script and a log of a conversation demonstrating the new tool in action.

-----
