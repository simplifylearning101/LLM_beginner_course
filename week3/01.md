Fantastic. Welcome to **Week 3: Advanced Applications & Agentic Systems**. We'll now combine the skills you've mastered into more sophisticated, multi-step applications. This week is all about building systems where the LLM becomes a reasoning and decision-making engine, not just a static text generator.

-----

### **Week 3: Hour 1 - LLM Chaining for Complex Workflows**

#### **30% Theory: Decomposing Problems with LLM Chaining**

  * **Objective:** To understand how to break a complex problem into a sequence of smaller, single-turn LLM calls, and to learn how to programmatically pass the output of one call as input for the next.

  * **What is LLM Chaining?**

      * Chaining is a fundamental technique where you connect the output of one LLM prompt to the input of a subsequent prompt.
      * Think of it like a chain of commands: `[Step 1: Get Info] -> [Step 2: Analyze Info] -> [Step 3: Generate Based on Analysis]`.

  * **Why Chain?**

      * **Simplicity:** Complex, multi-part prompts often fail. By breaking the task into smaller steps, you get more reliable and predictable outputs.
      * **Modularity:** Each step can be a dedicated function in your code, making it easier to debug, test, and reuse.
      * **Cost Control:** You can use a cheaper model for a simple extraction step and a more powerful, expensive model only for the final, critical generation step.
      * **Iterative Refinement:** It allows the LLM to "think" in stages. The output of an intermediate step (e.g., a summary or a list) can be a better input for the next stage than the original raw text.

  * **Chaining vs. Our Previous Work:**

      * In Week 2, our examples were mostly single-turn tasks (e.g., summarize this text).
      * Here, we'll build a sequential pipeline. The output of `get_llm_response_robust` from one function will be the input to the prompt of the next.

#### **70% Hands-on Session: Building a 3-Step Content Chain**

  * **Objective:** To build a Python script that takes a vague idea and uses a three-step LLM chain to generate a concrete marketing plan.

  * **Step-by-Step Instructions:**

    1.  **Preparation:**

          * Open VS Code and create a new file: `week3_hour1_chaining.py`.
          * Copy your robust LLM setup from Week 2 (imports, API key, `get_llm_response_robust` function). We'll rely on this heavily.
          * Add `import json` at the top.

    2.  **Task 1: Generate Concrete Ideas (Step 1 of the Chain):**

          * **Goal:** Turn a general concept into a list of specific, detailed ideas.

          * **Add the following code to your script:**

            ```python
            # ... (your existing setup code and get_llm_response_robust function) ...

            print("\n--- Task 1: Step 1 of 3 - Idea Generation ---")
            general_concept = "a mobile app for mental wellness"

            prompt_step1 = f"""
            Brainstorm three unique and innovative ideas for a {general_concept}.
            For each idea, provide a brief, one-sentence description.
            Respond in a numbered list format.
            """

            messages_step1 = [{"role": "user", "content": prompt_step1}]
            if 'OpenAI' in globals():
                messages_step1.insert(0, {"role": "system", "content": "You are a creative product designer."})

            try:
                ideas = get_llm_response_robust(messages_step1, LLM_MODEL, temp=0.8, max_response_tokens=150)
                print("Generated Ideas:\n", ideas)
            except Exception as e:
                print(f"Failed in Step 1: {e}")
                ideas = None
            ```

          * **Run the script.** This generates the input for our next step.

    3.  **Task 2: Select the Best Idea (Step 2 of the Chain):**

          * **Goal:** Take the generated list, analyze it, and select the most viable idea.

          * **Add this code to your script (it depends on `ideas` from Task 1):**

            ```python
            # ... (code from Task 1) ...

            if ideas:
                print("\n--- Task 2: Step 2 of 3 - Idea Selection ---")
                selection_prompt = f"""
                From the list of ideas below, select the most compelling and viable one.
                Explain your choice in one or two sentences. Then, provide the selected idea's full description.
                
                Ideas:
                ---
                {ideas}
                ---
                
                Respond in a clear, narrative format, not as a list.
                """

                messages_step2 = [{"role": "user", "content": selection_prompt}]
                if 'OpenAI' in globals():
                    messages_step2.insert(0, {"role": "system", "content": "You are a savvy business analyst."})

                try:
                    selected_idea_analysis = get_llm_response_robust(messages_step2, LLM_MODEL, temp=0.5, max_response_tokens=200)
                    print("Selected Idea Analysis:\n", selected_idea_analysis)
                except Exception as e:
                    print(f"Failed in Step 2: {e}")
                    selected_idea_analysis = None
            ```

          * **Run the script.** The LLM will now analyze its own previous output.

    4.  **Task 3: Generate a Marketing Plan (Step 3 of the Chain):**

          * **Goal:** Use the selected idea and analysis to generate a targeted marketing plan.

          * **Add this code to your script (it depends on `selected_idea_analysis` from Task 2):**

            ```python
            # ... (code from Task 1 and 2) ...

            if selected_idea_analysis:
                print("\n--- Task 3: Step 3 of 3 - Marketing Plan Generation ---")
                marketing_prompt = f"""
                Based on the following selected idea and its analysis, generate a concise marketing plan.
                The plan should include a slogan, a target audience, and two key marketing channels (e.g., social media, email).
                
                Idea and Analysis:
                ---
                {selected_idea_analysis}
                ---
                
                Format your response as a JSON object with keys: "slogan", "target_audience", and "marketing_channels" (a list of strings).
                """

                messages_step3 = [{"role": "user", "content": marketing_prompt}]
                if 'OpenAI' in globals():
                    messages_step3.insert(0, {"role": "system", "content": "You are a professional digital marketer."})
                
                try:
                    marketing_json_str = get_llm_response_robust(messages_step3, LLM_MODEL, temp=0.4, max_response_tokens=250, json_format=True)
                    print("Marketing Plan (Raw JSON):\n", marketing_json_str)
                    
                    marketing_plan = json.loads(marketing_json_str)
                    print("\nParsed Marketing Plan:")
                    print(json.dumps(marketing_plan, indent=2))
                except Exception as e:
                    print(f"Failed in Step 3 (or JSON parsing): {e}")
            ```

          * **Run the script.** You've now built a complete, multi-step LLM pipeline.

  * **Conclusion:** You've successfully built a sophisticated, multi-step LLM chain. This is a powerful pattern for building complex applications that require more than a single command.

#### **Homework for Hour 1**

  * **Exercise 1: Chained Review Analyzer.**
      * Create a new Python file.
      * Start with a raw, unstructured customer review (e.g., from an online product).
      * **Step 1:** In the first LLM call, extract key entities from the review into a JSON object. The JSON should include `product_name`, `pros` (list of strings), and `cons` (list of strings).
      * **Step 2:** Use the JSON output from Step 1 in a new LLM call to write a concise, neutral-toned summary of the review, focusing on both the positive and negative points.
      * **Submit:** Your script and its output.

-----

