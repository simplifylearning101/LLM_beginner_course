### **Week 3: Hour 2 - Introducing LLM Agents & Tool Use**

#### **30% Theory: LLMs as Reasoning Engines**

  * **Objective:** To understand the conceptual shift from simple chaining to an agentic architecture, where the LLM can make decisions about which "tools" to use to accomplish a goal.

  * **What is an LLM Agent?**

      * An agent is a system where an LLM is given a high-level goal and has the ability to **reason** about the best path to achieve it.
      * Unlike a fixed chain, an agent can decide:
          * Do I have enough information to answer?
          * Do I need to use a "tool" (like a calculator, web search, or database query)?
          * What is the best way to use that tool?

  * **The Agentic Loop:**

    1.  **Plan:** The agent receives a request and breaks it down into a plan (internally).
    2.  **Act:** The agent outputs a specific, machine-readable command (e.g., `ACTION: SEARCH[query]`).
    3.  **Observe:** Your Python code sees the `ACTION` command, executes the corresponding tool function (e.g., a real web search), and gets the result.
    4.  **Loop:** The result is then fed back to the LLM, which observes the new information and continues the loop until it can provide a final answer.

  * **LLM "Tools":**

      * A tool is a piece of code (a Python function, an API call, a database query) that you write.
      * The LLM knows nothing about what a tool *does* initially. It only knows its name and a description that you provide in the prompt.
      * **Example:** `tool_name="web_search", description="a tool to search the internet for up-to-date information."`

#### **70% Hands-on Session: Building a Simple Agent with Tools**

  * **Objective:** To build a script where an LLM agent decides whether to use a hardcoded "web search" tool or answer a question directly.

  * **Step-by-Step Instructions:**

    1.  **Preparation:**

          * Create a new file: `week3_hour2_agent.py`.
          * Copy your robust LLM setup from Week 2 (imports, API key, `get_llm_response_robust`).

    2.  **Task 1: Define Your Tools:**

          * **Goal:** Create a dictionary that maps tool names to Python functions and their descriptions.

          * **Add the following code to your script:**

            ```python
            # ... (your existing setup code and get_llm_response_robust function) ...
            import time

            # Define the "tools" the LLM can use
            # These are just simple Python functions for this example
            def get_current_date():
                """Returns the current date in YYYY-MM-DD format."""
                return f"Today's date is: {time.strftime('%Y-%m-%d')}"

            def get_weather_forecast(location: str):
                """Returns a simulated weather forecast for a given location."""
                if "London" in location:
                    return "The weather in London is 15°C and partly cloudy with a 20% chance of rain."
                elif "New York" in location:
                    return "The weather in New York is 22°C and sunny."
                else:
                    return f"Weather data not available for {location}."

            # A dictionary to look up tool functions by name
            TOOLS = {
                "get_current_date": get_current_date,
                "get_weather_forecast": get_weather_forecast
            }
            ```

    3.  **Task 2: The Agentic Prompt:**

          * **Goal:** Instruct the LLM on its role, the tools it has, and the specific output format it must use to call a tool.

          * **Add this code:**

            ```python
            # ... (code from Task 1) ...

            # The core agentic prompt
            AGENT_PROMPT = """
            You are a helpful assistant with access to the following tools:

            1. Name: get_current_date
               Description: Use this to get today's date. No input is required.
               Example Usage: get_current_date()

            2. Name: get_weather_forecast
               Description: Use this to get the weather forecast for a specified city.
               Example Usage: get_weather_forecast(location='New York')

            To use a tool, you must follow this exact format:
            <tool_use>
            <tool_name>[tool name]</tool_name>
            <parameters>
            <parameter>[parameter_name]</parameter>[parameter_value]</parameter>
            </parameters>
            </tool_use>

            If you can answer the question directly, or once you have used a tool and have the result, provide a final answer in natural language.
            """
            ```

            *(Note: This XML-like format is a common pattern for agent prompts as it's easy for both the LLM to generate and for your code to parse. We'll use a simpler version for the homework).*

    4.  **Task 3: Implement the Agentic Loop:**

          * **Goal:** Write a `while` loop that handles the conversation, checks the LLM's output for a tool call, and executes the tool if found.

          * **Add this code to the end of your script:**

            ```python
            # ... (code from Task 1 and 2) ...

            print("\n--- Simple Agent Chatbot ---")
            print("Ask me about today's date or the weather in London or New York.")
            print("Type 'quit' or 'exit' to end.")

            while True:
                user_input = input("\nYou: ").strip()
                if user_input.lower() in ["quit", "exit"]:
                    print("Goodbye!")
                    break

                messages = [{"role": "user", "content": AGENT_PROMPT + f"\nUser Question: {user_input}"}]
                if 'OpenAI' in globals():
                    messages.insert(0, {"role": "system", "content": "You are a helpful assistant with access to tools."})

                try:
                    raw_response = get_llm_response_robust(messages, LLM_MODEL, temp=0.0, max_response_tokens=150)
                    
                    # Simple check for tool use pattern
                    if "<tool_use>" in raw_response:
                        print("DEBUG: Agent decided to use a tool.")
                        # This is a simplified parser; real agents use regex or dedicated libraries
                        tool_name = raw_response.split("<tool_name>")[1].split("</tool_name>")[0]
                        
                        # Handle parameters
                        params_str = raw_response.split("<parameters>")[1].split("</parameters>")[0]
                        params = {}
                        if "<parameter>" in params_str:
                             param_name = params_str.split("<parameter>")[1].split("</parameter>")[0].split("</parameter>")[0].strip()
                             param_value = params_str.split("</parameter>")[0].split("<parameter>")[1].strip()
                             params = {param_name: param_value}
                            
                        if tool_name in TOOLS:
                            # Execute the tool
                            result = TOOLS[tool_name](**params)
                            
                            # Feed the result back to the LLM
                            final_answer_prompt = f"""
                            The previous tool call returned the following result:
                            ---
                            {result}
                            ---
                            Based on this information, answer the user's original question: '{user_input}'
                            """
                            messages_answer = [{"role": "user", "content": AGENT_PROMPT + final_answer_prompt}]
                            if 'OpenAI' in globals():
                                messages_answer.insert(0, {"role": "system", "content": "You are a helpful assistant with access to tools."})
                            
                            final_answer = get_llm_response_robust(messages_answer, LLM_MODEL, temp=0.0, max_response_tokens=150)
                            print("Assistant:", final_answer)
                        else:
                            print("Assistant: I'm sorry, I don't know how to use that tool.")
                    else:
                        print("Assistant:", raw_response)
                except Exception as e:
                    print(f"Assistant: An error occurred: {e}")
                    print("Please try again.")
            ```

          * **Run the script.** Ask a few questions like "What's the weather in New York?" and "What is the current date?". You'll see the agent decide to use a tool. Then ask a general question like "What is AI?" and see it answer directly.

  * **Conclusion:** You've built a basic LLM agent. By separating the LLM's reasoning from its actions (your Python code), you've created a modular and powerful system capable of making decisions and interacting with the outside world.

#### **Homework for Hour 2**

  * **Exercise 1: Add a New Tool.**
      * Add a new function to your `week3_hour2_agent.py` script called `check_holiday(date: str)`. This function should return a simple string (e.g., "It's a national holiday today." or "It is not a national holiday.").
      * Update the `AGENT_PROMPT` to include the description of your new tool and an example of how to use it.
      * Modify the agent's logic to handle the new tool call.
      * **Submit:** Your modified script and the output of a conversation where the LLM correctly uses the new tool.

-----
